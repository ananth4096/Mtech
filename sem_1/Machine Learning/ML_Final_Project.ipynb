{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14737bfc",
   "metadata": {},
   "source": [
    "## Importing Necessary Packages and Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d77c520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb90816e",
   "metadata": {},
   "source": [
    "## Reading Dataset from the Local "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c8787fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['Variance', 'Skewness', 'Curtosis', 'Entropy', 'Class']\n",
    "data = pd.read_csv(r\"D:\\1-1 sem\\Machine Learning\\banknote_dataset\\data_banknote_authentication.txt\", skiprows=1, header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cca717b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Curtosis</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.45860</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.92420</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.01120</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.57180</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.36840</td>\n",
       "      <td>9.6718</td>\n",
       "      <td>-3.96060</td>\n",
       "      <td>-3.16250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.59120</td>\n",
       "      <td>3.0129</td>\n",
       "      <td>0.72888</td>\n",
       "      <td>0.56421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.09220</td>\n",
       "      <td>-6.8100</td>\n",
       "      <td>8.46360</td>\n",
       "      <td>-0.60216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.20320</td>\n",
       "      <td>5.7588</td>\n",
       "      <td>-0.75345</td>\n",
       "      <td>-0.61251</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.53560</td>\n",
       "      <td>9.1772</td>\n",
       "      <td>-2.27180</td>\n",
       "      <td>-0.73535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.22470</td>\n",
       "      <td>8.7779</td>\n",
       "      <td>-2.21350</td>\n",
       "      <td>-0.80647</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variance  Skewness  Curtosis  Entropy  Class\n",
       "0   4.54590    8.1674  -2.45860 -1.46210      0\n",
       "1   3.86600   -2.6383   1.92420  0.10645      0\n",
       "2   3.45660    9.5228  -4.01120 -3.59440      0\n",
       "3   0.32924   -4.4552   4.57180 -0.98880      0\n",
       "4   4.36840    9.6718  -3.96060 -3.16250      0\n",
       "5   3.59120    3.0129   0.72888  0.56421      0\n",
       "6   2.09220   -6.8100   8.46360 -0.60216      0\n",
       "7   3.20320    5.7588  -0.75345 -0.61251      0\n",
       "8   1.53560    9.1772  -2.27180 -0.73535      0\n",
       "9   1.22470    8.7779  -2.21350 -0.80647      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f08141f",
   "metadata": {},
   "source": [
    "# Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9045c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_decision_tree = data.iloc[:, :-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00870db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_decision_tree = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f342da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_decision_tree, X_test_decision_tree, y_train_decision_tree, y_test_decision_tree = train_test_split(X_decision_tree, Y_decision_tree, test_size=0.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2685e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature = None, threshold = None, left = None, right = None, *, value = None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        \n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d924b26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    unique_labels, label_counts = np.unique(y, return_counts=True)\n",
    "    probabilities = label_counts / len(y)\n",
    "    entropy_value = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d8fc39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self, min_sample_split = 2, max_depth = 100, no_of_features = None):\n",
    "        self.min_sample_split = min_sample_split\n",
    "        self.max_depth = max_depth\n",
    "        self.no_of_features = no_of_features\n",
    "        self.root = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.no_of_features = X.shape[1] if not self.no_of_features else min(self.no_of_features, X.shape[1])\n",
    "        self.root = self._grow_tree(X, y)\n",
    "    \n",
    "    def _grow_tree(self, X, y, depth = 0):\n",
    "        no_of_samples, no_of_features = X.shape\n",
    "        no_of_labels = len(np.unique(y))\n",
    "        \n",
    "        #checking for the stopping criteria\n",
    "        if(depth >= self.max_depth or no_of_labels == 1 or no_of_samples < self.min_sample_split):\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value = leaf_value)\n",
    "        \n",
    "        #Selecting an array of feature indices randomly from the given features\n",
    "        feature_index = np.random.choice(no_of_features, self.no_of_features, replace = False)\n",
    "        \n",
    "        #greedy search for best splitting criteria\n",
    "        best_feature, best_threshold = self._best_criteria(X, y, feature_index)\n",
    "        left_idxs, right_idxs = self._split(X[:, best_feature], best_threshold)\n",
    "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], depth+1)\n",
    "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], depth+1)\n",
    "        \n",
    "        return Node(best_feature, best_threshold, left, right)\n",
    "    \n",
    "    def _best_criteria(self, X, y, feat_idxs):\n",
    "        best_gain = -1\n",
    "        split_index, split_threshold = None, None\n",
    "        \n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X[:, feat_idx]\n",
    "            thresholds = np.unique(X_column)\n",
    "            \n",
    "            for threshold in thresholds:\n",
    "                gain = self._information_gain(y, X_column, threshold)\n",
    "                \n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_index = feat_idx\n",
    "                    split_threshold = threshold\n",
    "                    \n",
    "        return split_index, split_threshold\n",
    "    \n",
    "    def _information_gain(self, y, X_column, split_threshold):\n",
    "        #calculate the parents entropy\n",
    "        parent_entropy = entropy(y)\n",
    "        \n",
    "        #generate split\n",
    "        left_idxs, right_idxs = self._split(X_column, split_threshold)\n",
    "        \n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "        \n",
    "        #calculate [weighted average]E(children)\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        e_l, e_r = entropy(y[left_idxs]), entropy(y[right_idxs])\n",
    "        child_entropy = (n_l/n)*e_l + (n_r/n)*e_r\n",
    "        \n",
    "        #return information gain = E(parent) - [weighted average]E(children)\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        \n",
    "        return information_gain\n",
    "        \n",
    "    def _split(self, X_column, split_threshold):\n",
    "        #gives an array of all the indices in X_column that follow the splitting criteria\n",
    "        left_idxs = np.argwhere(X_column <= split_threshold).flatten()\n",
    "        right_idxs = np.argwhere(X_column > split_threshold).flatten()\n",
    "        \n",
    "        return left_idxs, right_idxs\n",
    "        \n",
    "    def _most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        most_common = counter.most_common(1)[0][0]\n",
    "        return most_common\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "    \n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "        \n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        \n",
    "        return self._traverse_tree(x, node.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2e1bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Decision_Tree_Classifier = DecisionTree(max_depth = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "611c6353",
   "metadata": {},
   "outputs": [],
   "source": [
    "Decision_Tree_Classifier.fit(X_train_decision_tree, y_train_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a0a9554",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_decision_tree = Decision_Tree_Classifier.predict(X_test_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7edff98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pd.DataFrame(y_predicted_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70c6a4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=pd.DataFrame(y_test_decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d59b9d1",
   "metadata": {},
   "source": [
    "## Evaluation Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bba48b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[146   2]\n",
      " [  3 124]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffb478ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = conf_matrix[0][0]\n",
    "tn = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "fn = conf_matrix[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9f7c441",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f60f3bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatches =  conf_matrix.sum() - conf_matrix.trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a564f2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9818181818181818\n",
      "Precision: 0.9864864864864865\n",
      "Recall: 0.9798657718120806\n",
      "F1 Score: 0.9831649831649831\n",
      "Number of Mismatches: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAccuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n",
    "print(\"Number of Mismatches:\", mismatches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe09ce",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e020067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_logistic_train, x_logistic_test, y_logistic_train, y_logistic_test = train_test_split(X_decision_tree, Y_decision_tree, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f25eb0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_logistic_train)\n",
    "x_logistic_train_ = sc.transform(x_logistic_train)\n",
    "x_logistic_test = sc.transform(x_logistic_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4d278cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression( random_state=0)\n",
    "lr.fit(x_logistic_train_, y_logistic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4748ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(x_logistic_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d2c3f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec5c69e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[154   6]\n",
      " [  0 115]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "conf_matrix = confusion_matrix(y_logistic_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95e69fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = conf_matrix[0][0]\n",
    "tn = conf_matrix[1][1]\n",
    "fp = conf_matrix[0][1]\n",
    "fn = conf_matrix[1][0]\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "mismatches =  conf_matrix.sum() - conf_matrix.trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41400582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9781818181818182\n",
      "Precision: 0.9625\n",
      "Recall: 1.0\n",
      "F1 Score: 0.980891719745223\n",
      "Number of Mismatches: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAccuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n",
    "print(\"Number of Mismatches:\", mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07b2b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
